{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weak vs Strong Augmentation\n",
    "<img src=\"./docs/Figure_1.png\" alt=\"weak-strong-augment\" width=\"400\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Formulate:\n",
    "\n",
    "Here, we assume that there are only NUM_LABELS training samples, and large number of unlabelled images such that\n",
    "UNLABELLED_SAMPLES >> LABELLED_SAMPLES.\n",
    "\n",
    "This is quite common in real-world where annotation is expensive but unlabelled data are relatively available in abundance.\n",
    "\n",
    "Total Data available : ~1000\n",
    "\n",
    "What do we do?\n",
    "\n",
    "Because of non-availability of expert time, we were only able to obtain labels for 40 data.\n",
    "\n",
    "What accuracy were we able to obtain using the learning from last week? Supervised Learning.\n",
    "\n",
    "What do we do with the 960 images available to us? How do we leverage these images.\n",
    "\n",
    "Representation Learning: \n",
    "Show slides ... elaborate theory\n",
    "Classification Problem\n",
    "EfficientNet-B0 (show network diagram)\n",
    "if possible, visualize each layer representation and project using UMAP\n",
    "\n",
    "Are there ways to use alternatives to Supervised Paradigm for learning from data?\n",
    "Pretext-task, Contrastive, SemiSupervised Learning(Consistency Learning, Smoothness Assumption of Low), add figures example\n",
    "add more....\n",
    "\n",
    "Fixmatch:\n",
    "\n",
    "....\n",
    "\n",
    "code workflow\n",
    "\n",
    "weak and strong augmentation show\n",
    "\n",
    "pseudo label ...\n",
    "\n",
    "consistency loss ...\n",
    "\n",
    "// show the value of such a method from the improved results \n",
    "\n",
    "\n",
    "Assignment:\n",
    "\n",
    "Nuances: \n",
    "\n",
    "Augmentation: Basic\n",
    "\n",
    "CutMix:\n",
    "\n",
    "curicullum learning: easy to hard samples ... cutoff_threshold\n",
    "\n",
    "Exercises: Play with augmentations in this and your particular use cases.\n",
    "Exercise: as we get more labelled data, the leverage we get may vary\n",
    "the limited data we choose to label  \n",
    "\n",
    "Show Labelled Data and Unlabelled Data \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv_dataset import CSVDataset\n",
    "from transforms import get_data_transform\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root_dir = 'isic_challenge/ISBI2016_ISIC_Part3B_Training_Data'\n",
    "csv_path = 'isic_challenge/ISBI2016_ISIC_Part3B_Training_GroundTruth.csv'\n",
    "IMG_SIZE = 224\n",
    "img_transform = get_data_transform(IMG_SIZE)\n",
    "\n",
    "ISIC_LABELS  = ['benign','malignant']\n",
    "ISIC_LABELS_TO_IDX = {l:idx for idx, l in enumerate(ISIC_LABELS)}\n",
    "def isic_label_to_idx(label):\n",
    "    return ISIC_LABELS_TO_IDX[label]\n",
    "label_transform = torchvision.transforms.Lambda(isic_label_to_idx)\n",
    "\n",
    "isic_dataset = CSVDataset(data_root_dir,csv_path,img_transform,isic_label_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpef_ent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
